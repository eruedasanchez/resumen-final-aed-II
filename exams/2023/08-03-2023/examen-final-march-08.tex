\documentclass[10pt,a4paper]{article}
\usepackage[paper=a4paper,hmargin=0.5cm,bottom=1.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{xargs}
\usepackage{xspace}
\usepackage{caratula}
\usepackage{ifthen}
\usepackage{aed2-tad,aed2-symb,aed2-itef,aed2-diseno}
\usepackage{aed2-tad,aed2-symb,aed2-itef}
\usepackage{algorithmicx, algpseudocode, algorithm}
\usepackage{graphicx}


\materia{Algoritmos y Estructuras de Datos II}
\titulo{Examen Final}
\subtitulo{8 de marzo 2023}
\integrante{Ezequiel Rueda Sanchez}{522/16}{ezequiel.ruedasanchez@gmail.com}

\maketitle

\begin{document}

\section{Ejercicio 1}

Determine si las siguientes afirmaciones son verdaderas o falsas. Justifique.
\newline
\newline
a) El invariante vale en la pre pero no en la post de todas las funciones de la interfaz.
\newline
\newline
b) El invariante vale en la pre y en la post de todas las funciones de implementacion que se corresponden con funciones de la interfaz (ejemplo: iAgregar).
\newline
\newline
c) El invariante vale en la pre y en la post de todas las funciones auxiliares de la implementacion.
\newline
\newline
d) La funcion de abstraccion provee una explicacion de como se usa la estructura de representacion.
\newline
\newline
e) Por ende, determina la complejidad de las operaciones.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
a) La afirmacion es \textbf{verdadera} porque el invariante de representacion se tiene que cumplir en la precondicion y en la postcondicion de todas las funciones de la intefaz a excepcion de las funciones auxiliares definidas para el modulo.
\newline
\newline
b) La afirmacion es \textbf{verdadera} por lo mencionado en el item anterior dado que las funciones auxiliares no son funciones de implemetacion que se corresponden con funciones de la interfaz. 
\newline
\newline
c) La afirmacion es \textbf{falsa} porque justamente el invariante de representacion debe valer en la precondicion y postcondicion de las funciones del modulo pero no en las funciones auxiliares del mismo.
\newline
\newline
d) La afirmacion es \textbf{verdadera} porque nos permite vincular las distintas instancias validas de la estructura de representacion con el valor representado del TAD dado que con los observadores basicos podemos identificar de manera univoca a cualquier instancia.
\newline
\newline
e) COMPLETAR!!!
\newpage

\section{Ejercicio 2}

Un viejo estereo de auto funciona de la siguiente manera. Solo capta radio en las bandas AM, FM y SW (onda corta) y ademas de botones para seleccionar la banda tiene botones para subir y bajar la frecuencia de a 10Hz. Cada banda tiene un rango de frecuencias distinto, por lo que al cambiar de banda vuelve a la frecuencia en la que estaba la ultima vez que se selecciono dicha banda. El volumen esta fijo y tiene 5 botones para memorizar estaciones. Estos botones funcionan de la siguiente manera: si se los pulsa durante dos segundos memorizan la estacion actualmente seleccionada. Si se los presiona menos tiempo van a la estacion memorizada. Se propone la siguiente signtura del TAD \tadNombre{Estereo}.
\newline
\newline
\begin{tad}{\tadNombre{Empresa}}
	\medskip	
	\tadObservadores
	\medskip
	\tadOperacion{banda}{estereo}{nat}{}
	\medskip
	\tadOperacion{frecuencia}{estereo}{nat}{}
	\medskip
	
	\tadGeneradores
	\medskip
	\tadOperacion{nuevo}{}{estereo}{}
	\medskip
	\tadOperacion{cambiar\_frecuencia}{estereo, int}{estereo}{}
	\medskip
	\tadOperacion{cambiar\_banda}{estereo, nat}{estereo}{}
	\medskip
	\tadOperacion{presionar\_boton\_dos\_segundos}{estereo, nat}{estereo}{}
	\medskip
	\tadOperacion{presionar\_boton}{estereo, nat}{estereo}{}
	\medskip
	\medskip
	
	\tadAxiomas[$\forall$]
	
	\tadAlinearAxiomas{suma edades(llega\_empleado(crear\_empleado(d,e,l),a,f)}
	\medskip
	\tadAxioma{suma\_edades(crear(c))}{0}
	\medskip
	\tadAxioma{suma edades(llega\_empleado(crear\_empleado(d,e,l),a,f)}{e + suma\_edades(f)}
	\medskip
	\medskip

\end{tad}

Corregir los errores si los hubiera y presentar la axiomatizacion del observador \TipoVariable{frecuencia}.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
Comenzamos realizando las siguientes correcciones al TAD.
\newline
\newline
TAD \tadNombre{Banda} es \tadNombre{Enum\{AM,FM,SW\}} 
\newline
\newline
TAD \tadNombre{Rango} es \tadNombre{Tupla(nat,nat)} 
\newline
\begin{tad}{\tadNombre{Estereo}}
	\medskip	
	\tadObservadores
	\medskip
	\tadOperacion{frecuencia}{estereo, banda}{nat}{}
	\medskip
	\tadOperacion{rango}{estereo, banda}{rango}{}
	\medskip
	\tadOperacion{estacion\_memorizada}{estereo, nat/btn}{tupla(banda,nat)}{1 $\leq$ $btn$ $\leq$ 5}
	\medskip
	
	\tadGeneradores
	\medskip
	\tadOperacion{nuevo}{dicc(banda;rango)/dbr}{estereo}{$\neg$($\emptyset$?(claves($dbr$)))}
	\medskip
	\tadOperacion{subir\_frecuencia}{estereo, banda}{estereo}{}
	\medskip
	\tadOperacion{bajar\_frecuencia}{estereo, banda}{estereo}{}
	\medskip
	\tadOperacion{cambiar\_banda}{estereo, banda}{estereo}{}
	\medskip
	\tadOperacion{presionar\_boton\_dos\_segundos}{estereo, nat}{estereo}{}
	\medskip
	\tadOperacion{presionar\_boton}{estereo, nat}{estereo}{}
	\newpage
	\tadAxiomas[$\forall$ $e$:estereo, $dbr$:dicc(banda,rango), $b,b'$:banda, $btn$:nat]
	
	\tadAlinearAxiomas{frecuencia(presionar\_boton\_dos\_segundos(e,btn),b)}
	\medskip
	\tadAxioma{frecuencia(nuevo(dbr),b)}{$\pi_{1}$(obtener(b,dbr))}
	\medskip
	\medskip
	\tadAxioma{frecuencia(bajar\_frecuencia(e,b'),b)}{\IF b = b' THEN {\IF frecuencia(e,b') = $\pi_{1}$(rango(e,b')) THEN $\pi_{2}$(rango(e,b')) ELSE frecuencia(e,b') $-$ 10 FI}  ELSE frecuencia(e,b) FI}
	\medskip
	\medskip
	\tadAxioma{frecuencia(subir\_frecuencia(e,b'),b)}{\IF b = b' THEN {\IF frecuencia(e,b') = $\pi_{2}$(rango(e,b')) THEN $\pi_{1}$(rango(e,b')) ELSE frecuencia(e,b') $+$ 10 FI}  ELSE frecuencia(e,b) FI}
	\medskip
	\medskip
	\tadAxioma{frecuencia(cambiar\_banda(e,b'),b)}{frecuencia(e,b)}
	\medskip
	\medskip
	\tadAxioma{frecuencia(presionar\_boton\_dos\_segundos(e,btn),b)}{frecuencia(e,b)}
	\medskip
	\medskip
	\tadAxioma{frecuencia(presionar\_boton(e,btn),b)}{\IF $\pi_{1}$(estacion\_memorizada(e,btn)) = b THEN $\pi_{2}$(estacion\_memorizada(e,btn)) ELSE frecuencia(e,b) FI}
	\medskip
	\medskip
\end{tad}
\newpage

\section{Ejercicio 3}

Escribir un algoritmo Heapify bottom-up que utilice la estrategia Divide \& Conquer. Demostrar que la complejidad de este algoritmo recursivo se corresponde con la implementacion del algoritmo iterativo de Floyd visto en clase.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
Comenzamos presentando la implementacion del algoritmo de Floyd.

\begin{algorithm}[H]{\textbf{floydAlgorithm}(\Inout{A}{arreglo(nat)})}
	\begin{algorithmic}[1]
		\State $n$ $\gets$ tam($A$)                               
		\For{$i=\frac{n}{2}$; $i \geq 0$; $i--$}                  
		\State siftDown($q(A),i$)                                    
		\EndFor
		\medskip
	\end{algorithmic}
\end{algorithm}

Ahora, analizamos y calculamos la complejidad del algoritmo.
\newline
\newline
Comenzamos colocando las $n$ claves destinadas para nuestro heap en el mismo orden en el que
vienen. La forma del heap resultante es correcta ya que es completamente balanceado e izquierdista, pero las claves estan completamente desordenadas. 
\newline
\newline
Entonces, consideremos el arreglo en el orden inverso, empezando desde su $n$-esima posicion. Esta representa una hoja del arbol, por lo que si miramos unicamente el subarbol que la tiene como raiz, ese subarbol es un heap. Lo mismo ocurriria en el caso de las ultimas $\displaystyle \frac{n}{2}$ posiciones en el arreglo, al ser todas hojas (para que un nodo pueda tener hijos, la posicion $2i + 1$ debe ser una posicion valida dentro del heap). Si continuamos retrocediendo sobre el arreglo, vamos a encontrarnos con un primer nodo interno con hijos. Es posible que el subarbol enraizado en este elemento no sea un heap, pero sus hijos representan un heap bien formado. Por lo tanto, para recuperar la condicion de heap, podemos aplicar la operacion de \TipoVariable{siftDown} sobre la raiz de este subarbol. Siguiendo esta idea, podemos construir un heap aplicando $\displaystyle \frac{n}{2}$ llamadas no triviales a \TipoVariable{siftDown}.
\newline
\newline
Multiplicando la cantidad de llamadas a \TipoVariable{siftDown}, obtenemos una cota superior de $O(n~log(n))$. Sin embargo, esta es una cota superior, ya que solo la ultima llamada considera la totalidad del arbol. Por lo tanto, nos conviene hacer un analisis mas fino para estudiar la complejidad de este algoritmo.
\newline
\newline
Sabemos que en un arbol binario de $n$ = $2^{k} - 1$ nodos tenemos $\displaystyle \frac{(n+1)}{2}$ nodos que son hojas raices de un subarbol de altura 0, $\displaystyle \frac{(n+1)}{4}$ nodos que son hojas raices de un subarbol de altura 1, $\displaystyle \frac{(n+1)}{8}$ nodos que son hojas raices de un subarbol de altura 2, etc. Ademas, sabemos que el costo de SiftDown depende linealmente de la altura del subarbol considerado. En general, a lo sumo vamos a tener $\displaystyle \frac{(n+1)}{2^{h+1}}$ nodos de altura $h$.
\newline
\newline
Por lo tanto, $n_{h}$ $=$ $n_{i} + 1$ donde $n_{h}$ representa el numero de hojas y $n_{i}$ numero de nodos internos.
\newline
\newline
Ya tenemos una forma de contar cuantos nodos hay en cada nivel. Ahora, veamos la otra parte que esta determinando el costo del Algoritmo de Floyd, que es cuanta cantidad maxima de intercambios necesito hacer para un nodo en un nivel dado. 
\newline
\newline
Una llamada de bajar sobre un nodo de nivel $i$, provoca como máximo $k - i$ intercambios (op. dominante) 
\newline
\newline
\textbf{.} 1 intercambio si $i$ es penúltimo nivel, 2 si $i$ es el antepenúltimo, ..., $k-1$ intercambios si $i$ = 1
\newline
\newline
\# max de intercambios = 
\newline
\newline
(\# nodos en el penúltimo nivel) · 1 + (\# nodos en el antepenúltimo nivel) · 2 + ... + (\# nodos en el nivel 2) · ($k-2$) + 
\newline
\newline
(\# nodos en el nivel 1) · ($k-1$), con $k$ = $lg(n+1)$
\newline
\newline
\newline
\newline
\newline
Ahora, reemplazando las hojas y nodos de las diapositivas anteriores por la cantidad de intercambios obtenemos:
\newline
\newline
\# max de intercambios = 
\newline
\newline
($\displaystyle \frac{(n+1)}{4}$) · 1 + ($\displaystyle \frac{(n+1)}{8}$) · 2 + ... + 2 . ($log(n+1)$ - 2) + 1 . ($log(n+1)$ - 1) 
\newline
\newline
\newline
$\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{n+1}{2^{i}}(i-1)$ $=$ $(n+1)$ $\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{i-1}{2^{i}}$ $=$ $(n+1)$ ($\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{i}{2^{i}}$ $-$ $\displaystyle \sum_{i=2}^{log(n+1)} \displaystyle \frac{1}{2^{i}}$) 
\newline
\newline
\newline
Entonces, consideremos la primer y segunda mitad de la igualdad:
\newline
\newline
$\displaystyle \sum_{i=2}^{\infty}$ $\displaystyle \frac{i}{2^{i}}$ $=$ $\displaystyle \frac{3}{2}$~~~~~~~~~~~~~~~~~~$\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{1}{2^{i}}$ $>$ $0$
\newline
\newline
\newline
Deducimos que:
\newline
\newline
$(n+1)$ ($\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{i-1}{2^{i}}$ $<$ $(n+1)$ ($\displaystyle \frac{3}{2}$ $-$ $\displaystyle \sum_{i=2}^{log(n+1)}$ $\displaystyle \frac{1}{2^{i}}$) $<$ $\displaystyle \frac{3}{2}$ $(n+1)$ $\Rightarrow$ \# max de intercambios = $O(n)$.
\newpage

\section{Ejercicio 4}

a) Discutir el concepto de balanceo de los arboles B y de los arboles AVL ¿En que se parecen y en que se parecen ambos conceptos?
\newline
\newline
b) Discutir las diferencias y similitudes entre la implementacion de arboles B en la que se $"$parte al subir$"$ y en la que se $"$parte al bajar$"$.
\newline
\newline
\textbf{Resolucion}
\newpage

\section{Ejercicio 5}

Discutir la aplicabilidad de todos los metodos de ordenamiento al caso que la secuencia a ordenar este representada a traves de una lista encadenada (en lugar de un arreglo). Incluir en la discusion el analisis de complejidad correspondiente. 
\newline
\newline
\textbf{Resolucion}
\newline
\newline
\textbf{.} Caso Selection Sort
\newline
\newline
Este metodo de ordenamiento resulta aplicable porque en el caso donde la secuencia esta representada a traves de un arreglo, en cada iteracion $i$ del ciclo principal, se busca al elemento de menor valor entre las posiciones $i$ y $n$ donde $n$ representa el tamaño del arreglo y se lo intercambia con el elemento que se encuentra en la posicion $i$. Y si la implementacion se realiza sobre una lista enlazada, tambien se cuenta con la operacion para poder indexar elementos y de este modo, poder realizar los intercambios necesarios en cada iteracion. La complejidad sigue siendo $O(n^{2})$. 
\newline
\newline
\textbf{.} Caso Insertion Sort
\newline
\newline
Este metodo de ordenamiento resulta aplicable porque como en el caso de Selection Sort, necesitamos tener indexados a los elementos para poder accederlos e insertarlos en su posicion correspondiente en la lista. La complejidad sigue siendo $O(n^{2})$.
\newline
\newline
\textbf{.} Caso HeapSort
\newline
\newline
Este metodo de ordenamiento resulta aplicable porque tanto a los arreglos como a las listas enlazadas puedo representarlas como $heaps$ para poder aplicarles el Algoritmo de Floyd en el primer lugar y luego ir insertando los elementos en la lista en su posicion correspondiente a medida que los voy desencolando del heap. La complejidad sigue siendo $O(n~log(n))$.
\newline
\newline
\textbf{.} Caso MergeSort
\newline
\newline
Este metodo de ordenamiento resulta aplicable porque contamos con operaciones para indexar los elementos y calcular la longitud de la lista para poder partir la lista original por la mitad, ordenar recursivamente cada mitad y luego aplicarle la operacion de $merge$. La complejidad sigue siendo $O(n~log(n))$.
\newline
\newline
\textbf{.} Caso QuickSort
\newline
\newline
Este metodo de ordenamiento resulta aplicable porque es similar al caso de Mergesort donde, al tener una lista enlazada, contamos con la operacion para poder indexar elementos y de este modo, podemos elegir el $bound$ o $pivot$ que utilizaremos para colocar a los elementos menores a el en una sublista y a los elementos mayores a el en otra sublista; y repetir este procedimiento para cada sublista de manera recursiva hasta llegar al caso base. La complejidad sigue siendo $O(n^{2})$. 

\end{document}
