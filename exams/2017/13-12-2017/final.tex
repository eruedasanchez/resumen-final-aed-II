\documentclass[10pt,a4paper]{article}
\usepackage[paper=a4paper,hmargin=0.5cm,bottom=1.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{xargs}
\usepackage{xspace}
\usepackage{caratula}
\usepackage{ifthen}
\usepackage{aed2-tad,aed2-symb,aed2-itef,aed2-diseno}
\usepackage{aed2-tad,aed2-symb,aed2-itef}
\usepackage{algorithmicx, algpseudocode, algorithm}
\usepackage{graphicx}

\materia{Algoritmos y Estructuras de Datos II}
\titulo{Examen Final}
\subtitulo{13 de diciembre 2017}
\integrante{Ezequiel Rueda Sanchez}{522/16}{ezequiel.ruedasanchez@gmail.com}


\begin{document}


\maketitle

\section{Ejercicio 1}

Demostrar por qué la altura de un árbol de Fibonacci es logarítmica respecto a la cantidad de nodos.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
Para demostrar que la altura $h$ de un arbol de Fibonacci es logaritmica respecto a la cantidad de nodos, nos alcanza con probar que este arbol de altura $h$ de menor cantidad de nodos, tienen una cantidad exponencial de nodos en funcion de su altura. 
\newline
\newline
Para esto, podemos probar que la cantidad de nodos de un arbol de Fibonacci $Fibo_{h}$ $=$ $Fibo_{h-1}$ $+$ $Fibo_{h-2}$ $+$ $1$ y que 
\newline
$Fibo_{h}$ $=$ $Fibo_{h-2}$ $-$ $1$ siendo $Fibo_{i}$ es $i$-esimo termino de la sucesion de Fibonacci. Para ver esto, solo hace falta saber que se puede construir un arbol de Fibonacci de altura $h+2$ a partir de unir dos arboles: uno de altura $i$ con otro de altura $i+1$. A partir de esto, probamos que un arbol de $n$ nodos tiene una altura menor a 1.44 $log(n+2)$ $-$ $0.328$ por lo que queda demostrado que tiene una altura de $log(n)$.     
\newline
\newline
En el siguiente grafico, podemos ver como se van conformando los arboles de Fibonacci:

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{avl2}%
\caption{Conformacion de los Arboles de Fibonacci}
\label{drivers1}
\end{figure}

Ahora, vemos como se relacionan los Arboles de Fibonacci:

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\textwidth]{avl3}%
	\caption{Relacion de los Arboles de Fibonacci}
	\label{drivers1}
\end{figure}
\newpage

\section{Ejercicio 2}

Comparar los algoritmos de ordenamiento que son $O(n~log(n))$ en aspectos como uso de memoria adicional, hipótesis sobre el input, etc.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
Los algoritmos de ordenamiento vistos que tienen complejidad $O(n~log(n))$ son \textbf{HeapSort} y \textbf{MergeSort}. Entonces, analizamos cada uno de ellos.
\newline
\newline
El algoritmo de \textbf{HeapSort} no utiliza memoria adicional y con respecto al input, no es estable ya que es ineficaz con respecto a inputs del mismo valor.  
\newline
\newline
El algoritmo de \textbf{MergeSort} utiliza memoria adicional para ir almacenando los arreglos parcialmente ordenados y con respecto al input, generalmente es un algoritmo estable pero puede haber implementaciones que lo hagan inestable en el caso que ante igualdad de valores, se pase al arreglo ordenado el que se encuentra en la segunda mitad.  
\newpage

\section{Ejercicio 3}

Explicar los métodos de resolución de recurrencias vistos en la materia, y compararlos.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
La situación típica para estos casos es dividir en $a$ subproblemas, de tamaño máximo $\displaystyle \frac{n}{c}$, el costo de determinar subproblemas (divide) y unirlos (conquer) es $b n^{d}$. Suponemos que la base ($n=1$) cuesta $b$. 

\subsection{Solucion de la recurrencia tipica}

Costo (suponiendo $n = c^{k}$).
\newline
\newline
$T(n)$ $=$ $a$ $T(\displaystyle \frac{n}{c})$ $+$ $b n^{d}$ $=$ $a$ $T(c^{k-1})$ $+$ $b n^{d}$
\newline
\newline
$=$ $a(aT(c^{k-2}) + b c^{d(k-1)}) + bc^{kd}$ $=$ $a^{2}T(c^{k-2}) + abc^{d(k-1)} + bc^{kd}$ 
\newline
\newline
$=$ $a^{2}(aT(c^{k-3}) + b c^{d(k-2)}) + abc^{d(k-1)} + bc^{kd}$ 
\newline
\newline
$=$ $a^{3} T(c^{k-3}) + a^{2}b(c^{k-2})^{d} + abc^{d(k-1)} + bc^{kd}$ 
\newline
\newline
$=$ $a^{3} T(c^{k-3}) + a^{2}bc^{d(k-2)} + abc^{d(k-1)} + bc^{kd}$ 
\newline
\newline
Por lo tanto, en cada paso que realicemos vamos a obtener la siguiente expresion:
\newline
\newline
$a^{i} T(c^{k-j}) + \displaystyle \sum_{i=0}^{j-1} a^{i}bc^{d(k-1)}$
\newline
\newline
¿Hasta cuando realizamos estos pasos? Hasta que $c^{(k-j)} = 1$.
\newline
\newline
$c^{(k-j)} = 1$ $\Leftrightarrow$ $c^{k}$ $=$ $c^{j}$ $\Leftrightarrow$ $n$ $=$ $c^{j}$ $\Leftrightarrow$ $log(n)$ $=$ $log(c^{j})$ $\Leftrightarrow$ $log(n)$ $=$ $j$ $log(c)$ $\Leftrightarrow$ $\displaystyle \frac{log(n)}{log(c)}$ $=$ $j$ $\Leftrightarrow$ $log_{c}(n)$ $=$ $j$.
\newline
\newline
O sea, $j = log_{c}(n)$. Por lo tanto, obtenemos la siguiente expresion:
\newline
\newline
$a^{k}b + b \displaystyle \sum_{i=0}^{k-1} a^{i}c^{d(k-i)}$ donde $b$ significa que el costo del caso base es constante y se utiliza simplemente para poder operar de manera conveniente sobre la sumatoria.
\newline
\newline
\newline
$a^{k}b + b \displaystyle \sum_{i=0}^{k-1} a^{i}c^{d(k-i)}$ $=$ $b \displaystyle \sum_{i=0}^{k} a^{i}c^{d(k-i)}$ $=$ $b \displaystyle \sum_{i=0}^{k} a^{i}c^{dk-di}$ $=$ $bc^{dk} \displaystyle \sum_{i=0}^{k} a^{i}c^{-di}$ $=$ $bc^{dk} \displaystyle \sum_{i=0}^{k} \displaystyle \frac{a^{i}}{c^{di}}$ $=$ $b(c^{k})^{d} \displaystyle \sum_{i=0}^{k} (\displaystyle \frac{a}{c^{d}})^{i}$ $=$ $bn^{d} \displaystyle \sum_{i=0}^{log_{c}(n)} (\displaystyle \frac{a}{c^{d}})^{i}$

\subsubsection{Analisis por casos $bn^{d}$ $\displaystyle \sum_{i=0}^{log_{c}(n)}$ $(\displaystyle \frac{a}{c^{d}})^{i}$}

\textbf{.} Primer caso: $a = 1$, $d = 0$ (o sea, un solo subproblema, la combinación tiene costo constante) 
\newline
\newline
Entonces $bn^{d}$ $\displaystyle \sum_{i=0}^{log_{c}(n)}$ $(\displaystyle \frac{a}{c^{d}})^{i}$ $=$ $b$ $\displaystyle \sum_{i=0}^{log_{c}(n)} 1$ $=$ $O(log_{c}(n))$ donde un ejemplo de esto representa la Busqueda Binaria 
\newline
\newline
\newline
\textbf{.} Segundo Caso: $d = 1$ (o sea $"$conquer lineal$"$) 
\newline
\newline
1) Caso $a < c$ (o sea, $"$pocos subproblemas$"$) 
\newline
\newline
Como $\displaystyle \frac{a}{c} < 1$, la serie converge $\rightarrow$ $bn$ $\displaystyle \sum_{i=0}^{log_{c}(n)}$ $(\displaystyle \frac{a}{c})^{i}$ $=$ $bn$ . $const$ $=$ $O(n)$ 
\newline
\newline
\textbf{.} $d = 1$ (o sea $"$conquer lineal$"$) 
\newline
\newline
1) Caso $a = c$, $bn$ $\displaystyle \sum_{i=0}^{log_{c}(n)} 1$ $=$ $O(n~log_{c}(n))$ donde un ejemplo de esto representa
\newline
\newline
\newline
2) Caso $a > c$ (o sea, muchos subproblemas)
\newline
\newline
$bn$ $\displaystyle \sum_{i=0}^{log_{c}(n)}$ $(\displaystyle \frac{a}{c})^{i}$ $=$ $bn$ $\displaystyle \frac{(\displaystyle \frac{a}{c})^{log_{c}(n) + 1} - 1}{(\displaystyle \frac{a}{c})-1}$ por Serie Geometrica.
\newline
\newline
\newline
$bn$ $\displaystyle \frac{(\displaystyle \frac{a}{c})^{log_{c}(n) + 1} - 1}{(\displaystyle \frac{a}{c})-1}$ $\subset$ $O(n~(\displaystyle \frac{a}{c})^{log_{c}(n)})$ $=$ $O(n~.~\displaystyle \frac{a^{log_{c}(n)}}{c^{log_{c}(n)}})$ $=$ $O(n~.~\displaystyle \frac{a^{log_{c}(n)}}{n})$ $=$ $O(a^{log_{a}(n)~.~log_{c}(a)})$ $=$ $O((a^{log_{a}(n)})^{log_{c}(a)})$ $=$ $O(n^{log_{c}(a)})$ 

\subsection{Teorema Maestro (Master Theorem)}

Permite resolver relaciones de recurrencia de la forma:
\newline
\newline
$T(n) = \left\{ \begin{array}{lcc}
	aT(\displaystyle \frac{n}{c}) + f(n) &   si  & n > 1 \\
	\\          1 &   si  & n = 1     \\
\end{array}
\right.$
\newline
\newline
\newline
La solucion es:
\newline
\newline
$T(n)$ $=$ $\Theta(n^{log_{c}(a)})$ si $f(n)$ $=$ $O(n^{log_{c}(a) - \epsilon})$ para $\epsilon > 0$
\newline
\newline
$T(n)$ $=$ $\Theta(n^{log_{c}(a)}log(n))$ si $f(n)$ $=$ $\Theta(n^{log_{c}(a)})$ para $\epsilon > 0$
\newline
\newline
$T(n)$ $=$ $\Theta(f(n))$ si $f(n)$ $=$ $\Omega(n^{log_{c}(a) + \epsilon})$ para $\epsilon > 0$ y $af(\displaystyle \frac{n}{c}) < kf(n)$ para $k < 1$ y $n$ suficientemente grande. 
\newline
\newline
En los casos 1 y 3 es $T(n)$ $\in$ $\Theta(f(n) + n^{log_{c}(a)})$
\newline
\newline
Hay otras formulaciones con pequeñas variantes
\newpage

\section{Ejercicio 4}

Relacionar el invariante de representación con la complejidad temporal y la función de abstracción con la demostración de que un diseño es correcto respecto a su especificación.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
El invariante de representacion es una funcion booleana con dominio en el genero de representacion que devuelve $true$ cuando recibe una instancia valida. Por lo tanto, nos permite separar instancias validas de invalidas y de esta manera, lo podemos agregar a las postcondiciones, como una forma de garantizar que los algoritmos no rompen la estructura y sabemos que de acuerdo a la estructura elegida, se determina la complejidad de los algoritmos. Ademas, se agregan a las precondiciones como una garantia con la que cuentan los algoritmos logrando poder determinar que estructura de datos se va a poder elegir para la estructura de representacion la cual impacta directamente en la complejidad temporal.   
\newline
\newline
Luego, si la funcion de abstraccion es un homomorfismo respecto de la signatura del TAD, es decir, si la abstraccion de la implementacion de una determinada operacion $o$ es observacionalmente equivalente a la implementacion de la abstraccion de la operacion $o$, entonces queda demostrado que el diseño es correcto con respecto a su especificacion. 
\newpage

\section{Ejercicio 5}

Describir detalladamente qué son los observadores básicos y explicar por qué se los usa para definir las otras operaciones, y por qué mantienen las características del lenguaje.
\newline
\newline
\textbf{Resolucion}
\newline
\newline
Los \textbf{observadores basicos} son operaciones que nos permiten diferenciar instancias del TAD en clases de equivalencia. Las otras operaciones son el resto de las operaciones que se declaran en un TAD y en general, se axiomatizan en base a los observadores basicos para evitar que devuelvan valores que rompan con la $congruencia$ del TAD (en caso contrario, tendriamos que repensar si las incluimos a los observadores basicos). Por ultimo, los observadores mantienen las caracteristicas del lenguaje porque con ellos podemos escribir la igualdad observacional que nos indica cuando instancias del tipo son iguales. 

\end{document}











